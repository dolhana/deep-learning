{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IMDB_In_Keras.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"al26AJce1lnh","colab_type":"text"},"cell_type":"markdown","source":["# Analyzing IMDB Data in Keras"]},{"metadata":{"id":"aPYsPqAb1lnj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Imports\n","import numpy as np\n","import keras\n","from keras.datasets import imdb\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.preprocessing.text import Tokenizer\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","np.random.seed(42)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XRpbwogt1lnp","colab_type":"text"},"cell_type":"markdown","source":["## 1. Loading the data\n","This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at. We've set it at 1000, but feel free to experiment."]},{"metadata":{"id":"Y3xB4wsD1lnq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":52},"outputId":"2bece9e3-d979-45ae-9829-80dbb7366503","executionInfo":{"status":"ok","timestamp":1521928809190,"user_tz":420,"elapsed":4696,"user":{"displayName":"Handol Park","photoUrl":"//lh5.googleusercontent.com/-uCs_kkJz_iI/AAAAAAAAAAI/AAAAAAAArwk/Vi4gSmaUjAA/s50-c-k-no/photo.jpg","userId":"109203610264153414627"}}},"cell_type":"code","source":["# Loading the data (it's preloaded in Keras)\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1000)\n","\n","print(x_train.shape)\n","print(x_test.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["(25000,)\n","(25000,)\n"],"name":"stdout"}]},{"metadata":{"id":"BEh6iQtQ1lnu","colab_type":"text"},"cell_type":"markdown","source":["## 2. Examining the data\n","Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n","\n","The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."]},{"metadata":{"id":"PKnnvAZ51lnv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":72},"outputId":"4b5735e5-3d53-4bd4-963e-377bf3a4080c","executionInfo":{"status":"ok","timestamp":1521928811596,"user_tz":420,"elapsed":297,"user":{"displayName":"Handol Park","photoUrl":"//lh5.googleusercontent.com/-uCs_kkJz_iI/AAAAAAAAAAI/AAAAAAAArwk/Vi4gSmaUjAA/s50-c-k-no/photo.jpg","userId":"109203610264153414627"}}},"cell_type":"code","source":["print(x_train[0])\n","print(y_train[0])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n","1\n"],"name":"stdout"}]},{"metadata":{"id":"W812rZ5m1lny","colab_type":"text"},"cell_type":"markdown","source":["## 3. One-hot encoding the output\n","Here, we'll turn the input vectors into (0,1)-vectors. For example, if the pre-processed vector contains the number 14, then in the processed vector, the 14th entry will be 1."]},{"metadata":{"id":"TMJ0Z9_41lnz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":745},"outputId":"833d750c-7624-4cdb-a279-990dcacc07c8","executionInfo":{"status":"ok","timestamp":1521928817737,"user_tz":420,"elapsed":4465,"user":{"displayName":"Handol Park","photoUrl":"//lh5.googleusercontent.com/-uCs_kkJz_iI/AAAAAAAAAAI/AAAAAAAArwk/Vi4gSmaUjAA/s50-c-k-no/photo.jpg","userId":"109203610264153414627"}}},"cell_type":"code","source":["# One-hot encoding the output into vector mode, each of length 1000\n","tokenizer = Tokenizer(num_words=1000)\n","x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n","x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n","print(x_train[0])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n"," 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n"," 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n"," 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n"," 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"metadata":{"id":"fIRvRsP31loN","colab_type":"text"},"cell_type":"markdown","source":["And we'll also one-hot encode the output."]},{"metadata":{"id":"1WElyBeD1loN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":52},"outputId":"7022d3cf-e09b-41ac-dd1c-872160623618","executionInfo":{"status":"ok","timestamp":1521928819989,"user_tz":420,"elapsed":303,"user":{"displayName":"Handol Park","photoUrl":"//lh5.googleusercontent.com/-uCs_kkJz_iI/AAAAAAAAAAI/AAAAAAAArwk/Vi4gSmaUjAA/s50-c-k-no/photo.jpg","userId":"109203610264153414627"}}},"cell_type":"code","source":["# One-hot encoding the output\n","num_classes = 2\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","print(y_train.shape)\n","print(y_test.shape)\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(25000, 2)\n","(25000, 2)\n"],"name":"stdout"}]},{"metadata":{"id":"Uo6kxvDG1loQ","colab_type":"text"},"cell_type":"markdown","source":["## 4. Building the  model architecture\n","Build a model here using sequential. Feel free to experiment with different layers and sizes! Also, experiment adding dropout to reduce overfitting."]},{"metadata":{"id":"K4_OVY_S1loQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":277},"outputId":"e3e88d70-5ffb-4ec9-ea49-845bbdf6774e","executionInfo":{"status":"ok","timestamp":1521929944887,"user_tz":420,"elapsed":299,"user":{"displayName":"Handol Park","photoUrl":"//lh5.googleusercontent.com/-uCs_kkJz_iI/AAAAAAAAAAI/AAAAAAAArwk/Vi4gSmaUjAA/s50-c-k-no/photo.jpg","userId":"109203610264153414627"}}},"cell_type":"code","source":["# TODO: Build the model architecture\n","from keras.layers import Input, Dense, Dropout\n","from keras.models import Model\n","\n","inputs = Input(shape=(1000,))\n","layer_1 = Dense(1024, activation='relu')(inputs)\n","layer_1_dropout = Dropout(0.5)(layer_1)\n","output = Dense(2, activation='softmax')(layer_1_dropout)\n","\n","model = Model(inputs=inputs, outputs=output)\n","\n","# TODO: Compile the model using a loss function and an optimizer.\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":57,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_11 (InputLayer)        (None, 1000)              0         \n","_________________________________________________________________\n","dense_21 (Dense)             (None, 1024)              1025024   \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 1024)              0         \n","_________________________________________________________________\n","dense_22 (Dense)             (None, 2)                 2050      \n","=================================================================\n","Total params: 1,027,074\n","Trainable params: 1,027,074\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"0R6dGuBM1loU","colab_type":"text"},"cell_type":"markdown","source":["## 5. Training the model\n","Run the model here. Experiment with different batch_size, and number of epochs!"]},{"metadata":{"id":"QrrLxp6J1loU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":19},{"item_id":20}],"base_uri":"https://localhost:8080/","height":398},"outputId":"4e8a1c9f-533d-4e38-f81b-088a6941ef22","executionInfo":{"status":"ok","timestamp":1521929951361,"user_tz":420,"elapsed":5638,"user":{"displayName":"Handol Park","photoUrl":"//lh5.googleusercontent.com/-uCs_kkJz_iI/AAAAAAAAAAI/AAAAAAAArwk/Vi4gSmaUjAA/s50-c-k-no/photo.jpg","userId":"109203610264153414627"}}},"cell_type":"code","source":["# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n","model.fit(x_train, y_train, epochs=10, batch_size=1024, validation_data=(x_test, y_test), verbose=2)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/10\n"," - 1s - loss: 0.4773 - acc: 0.7668 - val_loss: 0.3444 - val_acc: 0.8543\n","Epoch 2/10\n"," - 0s - loss: 0.3256 - acc: 0.8636 - val_loss: 0.3274 - val_acc: 0.8599\n","Epoch 3/10\n"," - 0s - loss: 0.2921 - acc: 0.8795 - val_loss: 0.3239 - val_acc: 0.8593\n","Epoch 4/10\n"," - 0s - loss: 0.2711 - acc: 0.8885 - val_loss: 0.3277 - val_acc: 0.8586\n","Epoch 5/10\n"," - 0s - loss: 0.2463 - acc: 0.9026 - val_loss: 0.3327 - val_acc: 0.8578\n","Epoch 6/10\n"," - 0s - loss: 0.2170 - acc: 0.9162 - val_loss: 0.3242 - val_acc: 0.8610\n","Epoch 7/10\n"," - 0s - loss: 0.1887 - acc: 0.9318 - val_loss: 0.3253 - val_acc: 0.8619\n","Epoch 8/10\n"," - 0s - loss: 0.1602 - acc: 0.9455 - val_loss: 0.3290 - val_acc: 0.8608\n","Epoch 9/10\n"," - 0s - loss: 0.1300 - acc: 0.9605 - val_loss: 0.3369 - val_acc: 0.8598\n","Epoch 10/10\n"," - 0s - loss: 0.1054 - acc: 0.9724 - val_loss: 0.3432 - val_acc: 0.8601\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7feb0c2420f0>"]},"metadata":{"tags":[]},"execution_count":58}]},{"metadata":{"id":"cBjroaZO1loX","colab_type":"text"},"cell_type":"markdown","source":["## 6. Evaluating the model\n","This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?"]},{"metadata":{"id":"gyOlLNLW1loa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"ac91bd0c-779d-46d9-b872-7f386d07e4b3","executionInfo":{"status":"ok","timestamp":1521929959630,"user_tz":420,"elapsed":1781,"user":{"displayName":"Handol Park","photoUrl":"//lh5.googleusercontent.com/-uCs_kkJz_iI/AAAAAAAAAAI/AAAAAAAArwk/Vi4gSmaUjAA/s50-c-k-no/photo.jpg","userId":"109203610264153414627"}}},"cell_type":"code","source":["score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Accuracy: \", score[1])"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Accuracy:  0.86012\n"],"name":"stdout"}]}]}